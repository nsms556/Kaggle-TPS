{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Playground Series - Oct 2022\n",
    "  - Practice your ML skills on this approachable dataset!\n",
    "  - https://www.kaggle.com/competitions/tabular-playground-series-oct-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtypes = dict(pd.read_csv('datasets/train_dtypes.csv').set_index('column')['dtype'])\n",
    "\n",
    "def read_train_csv(file_no) :\n",
    "    return pd.read_csv('datasets/train_{}.csv'.format(file_no), dtype=train_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtypes = dict(pd.read_csv('datasets/test_dtypes.csv').set_index('column')['dtype'])\n",
    "\n",
    "test_origin = pd.read_csv('datasets/test.csv', dtype=test_dtypes).set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 장면 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_pos = ['ball_pos_x', 'ball_pos_y', 'ball_pos_z']\n",
    "\n",
    "for i in range(6) :\n",
    "    scene_pos.append('p{}_pos_x'.format(i))\n",
    "    scene_pos.append('p{}_pos_y'.format(i))\n",
    "    scene_pos.append('p{}_pos_z'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top, bottom, left, right, height, ground = 100, -100, 82, -82, 41, 0\n",
    "goal_left, goal_right, goal_height = 20, -20, 11\n",
    "top_limit, bottom_limit = 120, -120\n",
    "\n",
    "def position_3d(scene) :\n",
    "    ball = np.array((scene['ball_pos_x'], scene['ball_pos_y'], scene['ball_pos_z']))\n",
    "\n",
    "    player = np.zeros((6, 3))\n",
    "    for i in range(6) :\n",
    "        player[i] = [scene[f'p{i}_pos_x'], scene[f'p{i}_pos_y'], scene[f'p{i}_pos_z']]\n",
    "\n",
    "    return ball, player\n",
    "    \n",
    "def draw_field_top(ax) :\n",
    "    ax.vlines(bottom, right, left)\n",
    "    ax.vlines(top, right, left)\n",
    "\n",
    "    ax.hlines(goal_right, bottom_limit, bottom)\n",
    "    ax.hlines(goal_left, bottom_limit, bottom)\n",
    "    ax.hlines(goal_right, top, top_limit)\n",
    "    ax.hlines(goal_left, top, top_limit)\n",
    "\n",
    "def draw_field_side(ax) :\n",
    "    ax.vlines(bottom, ground-1, height)\n",
    "    ax.vlines(top, ground-1, height)\n",
    "\n",
    "    ax.hlines(goal_height, bottom_limit, bottom)\n",
    "    ax.hlines(goal_height, top, top_limit)\n",
    "\n",
    "def draw_scene(scene) :\n",
    "    ball_pos, players_pos = position_3d(scene)\n",
    "    p_colors = ['red', 'red', 'red', 'blue', 'blue', 'blue']\n",
    "    ball_color = 'black'\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(8, 10))\n",
    "\n",
    "    axes[0].set_ylim(right, left)\n",
    "    axes[0].set_xlim(bottom_limit, top_limit)\n",
    "    draw_field_top(axes[0])\n",
    "    axes[0].scatter(players_pos[:, 1], players_pos[:, 0], c = p_colors)\n",
    "    axes[0].scatter(ball_pos[1], ball_pos[0], c=ball_color)\n",
    "\n",
    "    axes[1].set_xlim(bottom_limit, top_limit)\n",
    "    axes[1].set_ylim(ground, height)\n",
    "    draw_field_side(axes[1])\n",
    "    axes[1].scatter(players_pos[:, 1], players_pos[:, 2], c = p_colors)\n",
    "    axes[1].scatter(ball_pos[1], ball_pos[2], c=ball_color)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = read_train_csv(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_scene(tmp_df.iloc[0][scene_pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21198036 entries, 0 to 2102812\n",
      "Data columns (total 50 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   ball_pos_x                   float32\n",
      " 1   ball_pos_y                   float32\n",
      " 2   ball_pos_z                   float32\n",
      " 3   ball_vel_x                   float32\n",
      " 4   ball_vel_y                   float32\n",
      " 5   ball_vel_z                   float32\n",
      " 6   p0_pos_x                     float32\n",
      " 7   p0_pos_y                     float32\n",
      " 8   p0_pos_z                     float32\n",
      " 9   p0_vel_x                     float32\n",
      " 10  p0_vel_y                     float32\n",
      " 11  p0_vel_z                     float32\n",
      " 12  p0_boost                     float16\n",
      " 13  p1_pos_x                     float32\n",
      " 14  p1_pos_y                     float32\n",
      " 15  p1_pos_z                     float32\n",
      " 16  p1_vel_x                     float32\n",
      " 17  p1_vel_y                     float32\n",
      " 18  p1_vel_z                     float32\n",
      " 19  p1_boost                     float16\n",
      " 20  p2_pos_x                     float32\n",
      " 21  p2_pos_y                     float32\n",
      " 22  p2_pos_z                     float32\n",
      " 23  p2_vel_x                     float32\n",
      " 24  p2_vel_y                     float32\n",
      " 25  p2_vel_z                     float32\n",
      " 26  p2_boost                     float16\n",
      " 27  p3_pos_x                     float32\n",
      " 28  p3_pos_y                     float32\n",
      " 29  p3_pos_z                     float32\n",
      " 30  p3_vel_x                     float32\n",
      " 31  p3_vel_y                     float32\n",
      " 32  p3_vel_z                     float32\n",
      " 33  p3_boost                     float16\n",
      " 34  p4_pos_x                     float32\n",
      " 35  p4_pos_y                     float32\n",
      " 36  p4_pos_z                     float32\n",
      " 37  p4_vel_x                     float32\n",
      " 38  p4_vel_y                     float32\n",
      " 39  p4_vel_z                     float32\n",
      " 40  p4_boost                     float16\n",
      " 41  p5_pos_x                     float32\n",
      " 42  p5_pos_y                     float32\n",
      " 43  p5_pos_z                     float32\n",
      " 44  p5_vel_x                     float32\n",
      " 45  p5_vel_y                     float32\n",
      " 46  p5_vel_z                     float32\n",
      " 47  p5_boost                     float16\n",
      " 48  team_A_scoring_within_10sec  int8   \n",
      " 49  team_B_scoring_within_10sec  int8   \n",
      "dtypes: float16(6), float32(42), int8(2)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['game_num', 'event_id', 'event_time'] + ['boost{}_timer'.format(i) for i in range(6)] + ['player_scoring_next', 'team_scoring_next']\n",
    "\n",
    "train_origin = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(10)) :\n",
    "    tmp_df = read_train_csv(i)\n",
    "    train_origin = pd.concat([train_origin, tmp_df])\n",
    "\n",
    "train_origin = train_origin.drop(drop_columns, axis=1)\n",
    "\n",
    "train_origin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ball_pos_x                     0\n",
       "ball_pos_y                     0\n",
       "ball_pos_z                     0\n",
       "ball_vel_x                     0\n",
       "ball_vel_y                     0\n",
       "ball_vel_z                     0\n",
       "p0_pos_x                       0\n",
       "p0_pos_y                       0\n",
       "p0_pos_z                       0\n",
       "p0_vel_x                       0\n",
       "p0_vel_y                       0\n",
       "p0_vel_z                       0\n",
       "p0_boost                       0\n",
       "p1_pos_x                       0\n",
       "p1_pos_y                       0\n",
       "p1_pos_z                       0\n",
       "p1_vel_x                       0\n",
       "p1_vel_y                       0\n",
       "p1_vel_z                       0\n",
       "p1_boost                       0\n",
       "p2_pos_x                       0\n",
       "p2_pos_y                       0\n",
       "p2_pos_z                       0\n",
       "p2_vel_x                       0\n",
       "p2_vel_y                       0\n",
       "p2_vel_z                       0\n",
       "p2_boost                       0\n",
       "p3_pos_x                       0\n",
       "p3_pos_y                       0\n",
       "p3_pos_z                       0\n",
       "p3_vel_x                       0\n",
       "p3_vel_y                       0\n",
       "p3_vel_z                       0\n",
       "p3_boost                       0\n",
       "p4_pos_x                       0\n",
       "p4_pos_y                       0\n",
       "p4_pos_z                       0\n",
       "p4_vel_x                       0\n",
       "p4_vel_y                       0\n",
       "p4_vel_z                       0\n",
       "p4_boost                       0\n",
       "p5_pos_x                       0\n",
       "p5_pos_y                       0\n",
       "p5_pos_z                       0\n",
       "p5_vel_x                       0\n",
       "p5_vel_y                       0\n",
       "p5_vel_z                       0\n",
       "p5_boost                       0\n",
       "team_A_scoring_within_10sec    0\n",
       "team_B_scoring_within_10sec    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(6) :\n",
    "    train_origin[f'p{i}_pos_x'].fillna(left, inplace=True)\n",
    "    train_origin[f'p{i}_pos_y'].fillna(top, inplace=True)\n",
    "    train_origin[f'p{i}_pos_z'].fillna(height, inplace=True)\n",
    "    train_origin[f'p{i}_vel_x'].fillna(0, inplace=True)\n",
    "    train_origin[f'p{i}_vel_y'].fillna(0, inplace=True)\n",
    "    train_origin[f'p{i}_vel_z'].fillna(0, inplace=True)\n",
    "    train_origin[f'p{i}_boost'].fillna(0, inplace=True)\n",
    "\n",
    "train_origin.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16958428, 48), (4239608, 48), (16958428, 2), (4239608, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = 22\n",
    "\n",
    "train_Y = train_origin[['team_A_scoring_within_10sec', 'team_B_scoring_within_10sec']]\n",
    "train_X = train_origin.drop(['team_A_scoring_within_10sec', 'team_B_scoring_within_10sec'], axis=1)\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=rs, shuffle=True)\n",
    "\n",
    "train_X.shape, val_X.shape, train_Y.shape, val_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(df) :\n",
    "    return torch.from_numpy(df.to_numpy())\n",
    "\n",
    "def convert_train_dataset(X, Y) :\n",
    "    return TensorDataset(to_tensor(X), to_tensor(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader) :\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_dataloader) :\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.float())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.round()\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    total *= 2\n",
    "    train_acc = correct / total * 100.\n",
    "    avg_loss = train_loss / total\n",
    "\n",
    "    return train_acc, avg_loss\n",
    "\n",
    "def validate(model, criterion, val_dataloader) :\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader) :\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, targets.float()).item()\n",
    "\n",
    "            predicted = outputs.round()\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    total *= 2\n",
    "    val_acc = correct / total * 100.\n",
    "    avg_loss = val_loss / total\n",
    "\n",
    "    return val_acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear1(nn.Module) :\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(48, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2151840 entries, 0 to 2151839\n",
      "Data columns (total 50 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   ball_pos_x                   float32\n",
      " 1   ball_pos_y                   float32\n",
      " 2   ball_pos_z                   float32\n",
      " 3   ball_vel_x                   float32\n",
      " 4   ball_vel_y                   float32\n",
      " 5   ball_vel_z                   float32\n",
      " 6   p0_pos_x                     float32\n",
      " 7   p0_pos_y                     float32\n",
      " 8   p0_pos_z                     float32\n",
      " 9   p0_vel_x                     float32\n",
      " 10  p0_vel_y                     float32\n",
      " 11  p0_vel_z                     float32\n",
      " 12  p0_boost                     float16\n",
      " 13  p1_pos_x                     float32\n",
      " 14  p1_pos_y                     float32\n",
      " 15  p1_pos_z                     float32\n",
      " 16  p1_vel_x                     float32\n",
      " 17  p1_vel_y                     float32\n",
      " 18  p1_vel_z                     float32\n",
      " 19  p1_boost                     float16\n",
      " 20  p2_pos_x                     float32\n",
      " 21  p2_pos_y                     float32\n",
      " 22  p2_pos_z                     float32\n",
      " 23  p2_vel_x                     float32\n",
      " 24  p2_vel_y                     float32\n",
      " 25  p2_vel_z                     float32\n",
      " 26  p2_boost                     float16\n",
      " 27  p3_pos_x                     float32\n",
      " 28  p3_pos_y                     float32\n",
      " 29  p3_pos_z                     float32\n",
      " 30  p3_vel_x                     float32\n",
      " 31  p3_vel_y                     float32\n",
      " 32  p3_vel_z                     float32\n",
      " 33  p3_boost                     float16\n",
      " 34  p4_pos_x                     float32\n",
      " 35  p4_pos_y                     float32\n",
      " 36  p4_pos_z                     float32\n",
      " 37  p4_vel_x                     float32\n",
      " 38  p4_vel_y                     float32\n",
      " 39  p4_vel_z                     float32\n",
      " 40  p4_boost                     float16\n",
      " 41  p5_pos_x                     float32\n",
      " 42  p5_pos_y                     float32\n",
      " 43  p5_pos_z                     float32\n",
      " 44  p5_vel_x                     float32\n",
      " 45  p5_vel_y                     float32\n",
      " 46  p5_vel_z                     float32\n",
      " 47  p5_boost                     float16\n",
      " 48  team_A_scoring_within_10sec  int8   \n",
      " 49  team_B_scoring_within_10sec  int8   \n",
      "dtypes: float16(6), float32(42), int8(2)\n",
      "memory usage: 373.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_origin = read_train_csv(8)\n",
    "drop_columns = ['game_num', 'event_id', 'event_time'] + ['boost{}_timer'.format(i) for i in range(6)] + ['player_scoring_next', 'team_scoring_next']\n",
    "\n",
    "train_origin = train_origin.drop(drop_columns, axis=1)\n",
    "\n",
    "for i in range(6) :\n",
    "    train_origin[f'p{i}_pos_x'].fillna(left, inplace=True)\n",
    "    train_origin[f'p{i}_pos_y'].fillna(top, inplace=True)\n",
    "    train_origin[f'p{i}_pos_z'].fillna(height, inplace=True)\n",
    "    train_origin[f'p{i}_vel_x'].fillna(0, inplace=True)\n",
    "    train_origin[f'p{i}_vel_y'].fillna(0, inplace=True)\n",
    "    train_origin[f'p{i}_vel_z'].fillna(0, inplace=True)\n",
    "    train_origin[f'p{i}_boost'].fillna(0, inplace=True)\n",
    "\n",
    "train_origin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1721472, 48), (430368, 48), (1721472, 2), (430368, 2))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y = train_origin[['team_A_scoring_within_10sec', 'team_B_scoring_within_10sec']]\n",
    "train_X = train_origin.drop(['team_A_scoring_within_10sec', 'team_B_scoring_within_10sec'], axis=1)\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.2, shuffle=True)\n",
    "\n",
    "train_X.shape, val_X.shape, train_Y.shape, val_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = convert_train_dataset(train_X, train_Y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "val_dataset = convert_train_dataset(val_X, val_Y)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Linear1().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch : 0 ---\n",
      "Train Loss : 0.00047071252187306183\n",
      "Train Acc : 93.92705687221431\n",
      "--- Epoch : 0 ---\n",
      "Val Loss : 0.00044684942848148876\n",
      "Val Acc : 94.27126829302335\n",
      "--- Epoch : 1 ---\n",
      "Train Loss : 0.0004459692240074583\n",
      "Train Acc : 94.2837876503922\n",
      "--- Epoch : 1 ---\n",
      "Val Loss : 0.00044620459822448407\n",
      "Val Acc : 94.28138746664743\n",
      "--- Epoch : 2 ---\n",
      "Train Loss : 0.0004455343148861901\n",
      "Train Acc : 94.29079548520969\n",
      "--- Epoch : 2 ---\n",
      "Val Loss : 0.00044595045861558157\n",
      "Val Acc : 94.2842952751601\n",
      "--- Epoch : 3 ---\n",
      "Train Loss : 0.00044532631607869475\n",
      "Train Acc : 94.2933834408062\n",
      "--- Epoch : 3 ---\n",
      "Val Loss : 0.0004457690329591203\n",
      "Val Acc : 94.28708677133227\n",
      "--- Epoch : 4 ---\n",
      "Train Loss : 0.0004451762871730034\n",
      "Train Acc : 94.29469195768083\n",
      "--- Epoch : 4 ---\n",
      "Val Loss : 0.00044562304778278985\n",
      "Val Acc : 94.2876683330348\n",
      "--- Epoch : 5 ---\n",
      "Train Loss : 0.00044505326412569587\n",
      "Train Acc : 94.29637849054146\n",
      "--- Epoch : 5 ---\n",
      "Val Loss : 0.00044550327089483633\n",
      "Val Acc : 94.2895293304829\n",
      "--- Epoch : 6 ---\n",
      "Train Loss : 0.0004449419837921374\n",
      "Train Acc : 94.29698913174963\n",
      "--- Epoch : 6 ---\n",
      "Val Loss : 0.00044538865789785654\n",
      "Val Acc : 94.29034351686644\n",
      "--- Epoch : 7 ---\n",
      "Train Loss : 0.00044482227198955603\n",
      "Train Acc : 94.29780332002717\n",
      "--- Epoch : 7 ---\n",
      "Val Loss : 0.00044525572765976516\n",
      "Val Acc : 94.29045982920697\n",
      "--- Epoch : 8 ---\n",
      "Train Loss : 0.0004446770740064477\n",
      "Train Acc : 94.2987338209158\n",
      "--- Epoch : 8 ---\n",
      "Val Loss : 0.00044509796603351255\n",
      "Val Acc : 94.28999457984494\n",
      "--- Epoch : 9 ---\n",
      "Train Loss : 0.000444482097036002\n",
      "Train Acc : 94.29919907136012\n",
      "--- Epoch : 9 ---\n",
      "Val Loss : 0.0004448889097907595\n",
      "Val Acc : 94.29197188963354\n",
      "--- Epoch : 10 ---\n",
      "Train Loss : 0.0004442651050984904\n",
      "Train Acc : 94.30024588485982\n",
      "--- Epoch : 10 ---\n",
      "Val Loss : 0.0004447087150860602\n",
      "Val Acc : 94.28918039346138\n",
      "--- Epoch : 11 ---\n",
      "Train Loss : 0.0004440214529351651\n",
      "Train Acc : 94.29978063441551\n",
      "--- Epoch : 11 ---\n",
      "Val Loss : 0.00044444718399739864\n",
      "Val Acc : 94.29255345133608\n",
      "--- Epoch : 12 ---\n",
      "Train Loss : 0.00044373792306561107\n",
      "Train Acc : 94.30204873033153\n",
      "--- Epoch : 12 ---\n",
      "Val Loss : 0.00044421398603736303\n",
      "Val Acc : 94.29453076112469\n",
      "--- Epoch : 13 ---\n",
      "Train Loss : 0.0004435087768814097\n",
      "Train Acc : 94.30449129516418\n",
      "--- Epoch : 13 ---\n",
      "Val Loss : 0.0004440162548917803\n",
      "Val Acc : 94.29522863516773\n",
      "--- Epoch : 14 ---\n",
      "Train Loss : 0.00044331743560575273\n",
      "Train Acc : 94.30707925076068\n",
      "--- Epoch : 14 ---\n",
      "Val Loss : 0.00044384444393839965\n",
      "Val Acc : 94.29615913389179\n",
      "--- Epoch : 15 ---\n",
      "Train Loss : 0.00044314165666560094\n",
      "Train Acc : 94.30864947101024\n",
      "--- Epoch : 15 ---\n",
      "Val Loss : 0.00044370380621783234\n",
      "Val Acc : 94.29627544623229\n",
      "--- Epoch : 16 ---\n",
      "Train Loss : 0.0004429771138651007\n",
      "Train Acc : 94.30876578362133\n",
      "--- Epoch : 16 ---\n",
      "Val Loss : 0.0004435789238599639\n",
      "Val Acc : 94.29662438325381\n",
      "--- Epoch : 17 ---\n",
      "Train Loss : 0.0004428183223498681\n",
      "Train Acc : 94.30891117438517\n",
      "--- Epoch : 17 ---\n",
      "Val Loss : 0.00044343644320097485\n",
      "Val Acc : 94.29639175857281\n",
      "--- Epoch : 18 ---\n",
      "Train Loss : 0.0004426462747363059\n",
      "Train Acc : 94.30879486177409\n",
      "--- Epoch : 18 ---\n",
      "Val Loss : 0.00044327462114899396\n",
      "Val Acc : 94.2981364436804\n",
      "--- Epoch : 19 ---\n",
      "Train Loss : 0.00044245377739101646\n",
      "Train Acc : 94.30940550298226\n",
      "--- Epoch : 19 ---\n",
      "Val Loss : 0.00044310567950458797\n",
      "Val Acc : 94.29720594495635\n",
      "--- Epoch : 20 ---\n",
      "Train Loss : 0.0004422488280781418\n",
      "Train Acc : 94.30879486177409\n",
      "--- Epoch : 20 ---\n",
      "Val Loss : 0.00044291852442581835\n",
      "Val Acc : 94.29534494750824\n",
      "--- Epoch : 21 ---\n",
      "Train Loss : 0.00044202188813565374\n",
      "Train Acc : 94.30748634489946\n",
      "--- Epoch : 21 ---\n",
      "Val Loss : 0.0004427027060180584\n",
      "Val Acc : 94.29615913389179\n",
      "--- Epoch : 22 ---\n",
      "Train Loss : 0.00044175974842365954\n",
      "Train Acc : 94.30707925076068\n",
      "--- Epoch : 22 ---\n",
      "Val Loss : 0.00044245772816136773\n",
      "Val Acc : 94.29639175857281\n",
      "--- Epoch : 23 ---\n",
      "Train Loss : 0.00044144479217757466\n",
      "Train Acc : 94.30510193637235\n",
      "--- Epoch : 23 ---\n",
      "Val Loss : 0.00044215478642127906\n",
      "Val Acc : 94.29232082665506\n",
      "--- Epoch : 24 ---\n",
      "Train Loss : 0.00044104008006469843\n",
      "Train Acc : 94.30356079427555\n",
      "--- Epoch : 24 ---\n",
      "Val Loss : 0.00044174392915364365\n",
      "Val Acc : 94.29243713899558\n",
      "--- Epoch : 25 ---\n",
      "Train Loss : 0.0004404574344314859\n",
      "Train Acc : 94.30193241772045\n",
      "--- Epoch : 25 ---\n",
      "Val Loss : 0.0004410806002731719\n",
      "Val Acc : 94.28871514409936\n",
      "--- Epoch : 26 ---\n",
      "Train Loss : 0.0004393502192585824\n",
      "Train Acc : 94.29387776940327\n",
      "--- Epoch : 26 ---\n",
      "Val Loss : 0.0004393781580641998\n",
      "Val Acc : 94.26510373897649\n",
      "--- Epoch : 27 ---\n",
      "Train Loss : 0.0004358304304655701\n",
      "Train Acc : 94.27875712996307\n",
      "--- Epoch : 27 ---\n",
      "Val Loss : 0.00043356393492610695\n",
      "Val Acc : 94.2599859959942\n",
      "--- Epoch : 28 ---\n",
      "Train Loss : 0.0004309148582861783\n",
      "Train Acc : 94.29445933245866\n",
      "--- Epoch : 28 ---\n",
      "Val Loss : 0.00042969627612795175\n",
      "Val Acc : 94.27371085217399\n",
      "--- Epoch : 29 ---\n",
      "Train Loss : 0.00042801982897692223\n",
      "Train Acc : 94.29928630581841\n",
      "--- Epoch : 29 ---\n",
      "Val Loss : 0.0004271848008354017\n",
      "Val Acc : 94.2789449074968\n",
      "--- Epoch : 30 ---\n",
      "Train Loss : 0.00042574645924492194\n",
      "Train Acc : 94.3037061850394\n",
      "--- Epoch : 30 ---\n",
      "Val Loss : 0.00042567935625063174\n",
      "Val Acc : 94.282666902393\n",
      "--- Epoch : 31 ---\n",
      "Train Loss : 0.00042520399430136946\n",
      "Train Acc : 94.30594520280266\n",
      "--- Epoch : 31 ---\n",
      "Val Loss : 0.0004255308539538644\n",
      "Val Acc : 94.282434277712\n",
      "--- Epoch : 32 ---\n",
      "Train Loss : 0.00042507386849182277\n",
      "Train Acc : 94.30635229694144\n",
      "--- Epoch : 32 ---\n",
      "Val Loss : 0.00042541140932880576\n",
      "Val Acc : 94.28220165303098\n",
      "--- Epoch : 33 ---\n",
      "Train Loss : 0.00042494264784767046\n",
      "Train Acc : 94.30597428095544\n",
      "--- Epoch : 33 ---\n",
      "Val Loss : 0.00042527773506200226\n",
      "Val Acc : 94.28301583941453\n",
      "--- Epoch : 34 ---\n",
      "Train Loss : 0.0004247986372131612\n",
      "Train Acc : 94.3053345615945\n",
      "--- Epoch : 34 ---\n",
      "Val Loss : 0.00042512146856410026\n",
      "Val Acc : 94.28371371345757\n",
      "--- Epoch : 35 ---\n",
      "Train Loss : 0.0004246338643431208\n",
      "Train Acc : 94.30475299853912\n",
      "--- Epoch : 35 ---\n",
      "Val Loss : 0.0004249276436529169\n",
      "Val Acc : 94.28383002579808\n",
      "--- Epoch : 36 ---\n",
      "Train Loss : 0.0004244349394725503\n",
      "Train Acc : 94.30379341949772\n",
      "--- Epoch : 36 ---\n",
      "Val Loss : 0.000424671273420478\n",
      "Val Acc : 94.28534208622466\n",
      "--- Epoch : 37 ---\n",
      "Train Loss : 0.00042418264051676647\n",
      "Train Acc : 94.30364802873386\n",
      "--- Epoch : 37 ---\n",
      "Val Loss : 0.0004243604526066819\n",
      "Val Acc : 94.28685414665125\n",
      "--- Epoch : 38 ---\n",
      "Train Loss : 0.0004238798769841958\n",
      "Train Acc : 94.30489838930296\n",
      "--- Epoch : 38 ---\n",
      "Val Loss : 0.0004240032094993382\n",
      "Val Acc : 94.28894776878037\n",
      "--- Epoch : 39 ---\n",
      "Train Loss : 0.0004235135610426496\n",
      "Train Acc : 94.30469484223357\n",
      "--- Epoch : 39 ---\n",
      "Val Loss : 0.0004235591132301162\n",
      "Val Acc : 94.2876683330348\n",
      "--- Epoch : 40 ---\n",
      "Train Loss : 0.00042303489282660364\n",
      "Train Acc : 94.3039969665671\n",
      "--- Epoch : 40 ---\n",
      "Val Loss : 0.00042297688535312587\n",
      "Val Acc : 94.28813358239682\n",
      "--- Epoch : 41 ---\n",
      "Train Loss : 0.00042233060355602325\n",
      "Train Acc : 94.30053666638752\n",
      "--- Epoch : 41 ---\n",
      "Val Loss : 0.00042210893577547575\n",
      "Val Acc : 94.28301583941453\n",
      "--- Epoch : 42 ---\n",
      "Train Loss : 0.00042110744620300883\n",
      "Train Acc : 94.29521536443067\n",
      "--- Epoch : 42 ---\n",
      "Val Loss : 0.0004204002730543789\n",
      "Val Acc : 94.2876683330348\n",
      "--- Epoch : 43 ---\n",
      "Train Loss : 0.0004155042253561754\n",
      "Train Acc : 94.29216215838986\n",
      "--- Epoch : 43 ---\n",
      "Val Loss : 0.000410536635853215\n",
      "Val Acc : 94.29162295261203\n",
      "--- Epoch : 44 ---\n",
      "Train Loss : 0.000409757979956759\n",
      "Train Acc : 94.30106007313736\n",
      "--- Epoch : 44 ---\n",
      "Val Loss : 0.00040941026083933204\n",
      "Val Acc : 94.2944144487842\n",
      "--- Epoch : 45 ---\n",
      "Train Loss : 0.0004092929256000475\n",
      "Train Acc : 94.30402604471986\n",
      "--- Epoch : 45 ---\n",
      "Val Loss : 0.00040924372126806914\n",
      "Val Acc : 94.29418182410318\n",
      "--- Epoch : 46 ---\n",
      "Train Loss : 0.0004091834005885517\n",
      "Train Acc : 94.30478207669188\n",
      "--- Epoch : 46 ---\n",
      "Val Loss : 0.0004091500519663092\n",
      "Val Acc : 94.29487969814622\n",
      "--- Epoch : 47 ---\n",
      "Train Loss : 0.00040908462856024155\n",
      "Train Acc : 94.30510193637235\n",
      "--- Epoch : 47 ---\n",
      "Val Loss : 0.0004090586240328747\n",
      "Val Acc : 94.29592650921077\n",
      "--- Epoch : 48 ---\n",
      "Train Loss : 0.00040898680640055084\n",
      "Train Acc : 94.30527640528896\n",
      "--- Epoch : 48 ---\n",
      "Val Loss : 0.00040896824645743086\n",
      "Val Acc : 94.29674069559432\n",
      "--- Epoch : 49 ---\n",
      "Train Loss : 0.000408889996153658\n",
      "Train Acc : 94.30579981203881\n",
      "--- Epoch : 49 ---\n",
      "Val Loss : 0.00040887893328882805\n",
      "Val Acc : 94.29755488197786\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss, val_acc, val_loss = run(net, criterion, optimizer, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_onefile(train_origin) :\n",
    "    drop_columns = ['game_num', 'event_id', 'event_time'] + ['boost{}_timer'.format(i) for i in range(6)] + ['player_scoring_next', 'team_scoring_next']\n",
    "\n",
    "    train_origin = train_origin.drop(drop_columns, axis=1)\n",
    "\n",
    "    for i in range(6) :\n",
    "        train_origin[f'p{i}_pos_x'].fillna(left, inplace=True)\n",
    "        train_origin[f'p{i}_pos_y'].fillna(top, inplace=True)\n",
    "        train_origin[f'p{i}_pos_z'].fillna(height, inplace=True)\n",
    "        train_origin[f'p{i}_vel_x'].fillna(0, inplace=True)\n",
    "        train_origin[f'p{i}_vel_y'].fillna(0, inplace=True)\n",
    "        train_origin[f'p{i}_vel_z'].fillna(0, inplace=True)\n",
    "        train_origin[f'p{i}_boost'].fillna(0, inplace=True)\n",
    "\n",
    "    train_Y = train_origin[['team_A_scoring_within_10sec', 'team_B_scoring_within_10sec']]\n",
    "    train_X = train_origin.drop(['team_A_scoring_within_10sec', 'team_B_scoring_within_10sec'], axis=1)\n",
    "\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.2, shuffle=True)\n",
    "\n",
    "    train_dataset = convert_train_dataset(train_X, train_Y)\n",
    "    val_dataset = convert_train_dataset(val_X, val_Y)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def run(model, criterion, optimizer, epochs, train_loader, val_loader, log=True) :\n",
    "    train_loss = []\n",
    "    train_acc= []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    save_loss = float('inf')\n",
    "\n",
    "    for i in range(epochs) :\n",
    "        acc, loss = train(model, optimizer, criterion, train_loader)\n",
    "        train_acc.append(acc)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        if log :\n",
    "            print('--- Epoch : {} ---'.format(i))\n",
    "            print('Train Loss : {}'.format(loss))\n",
    "            print('Train Acc : {}'.format(acc))\n",
    "\n",
    "        acc, loss = validate(model, criterion, val_loader)\n",
    "        val_acc.append(acc)\n",
    "        val_loss.append(loss)\n",
    "\n",
    "        if log :\n",
    "            print('--- Epoch : {} ---'.format(i))\n",
    "            print('Val Loss : {}'.format(loss))\n",
    "            print('Val Acc : {}'.format(acc))\n",
    "        \n",
    "        if loss < save_loss :\n",
    "            torch.save(model, 'model.pt')\n",
    "            save_loss = loss\n",
    "\n",
    "    return train_acc, train_loss, val_acc, val_loss\n",
    "\n",
    "def plot_all(train_acc, train_loss, val_acc, val_loss) :\n",
    "    fig, axes = plt.subplots(2, 1)\n",
    "\n",
    "    pd.DataFrame({'train' : train_acc, 'val':val_acc}).plot(ax=axes[0])\n",
    "    axes[0].set_title('Accuracy')\n",
    "    \n",
    "    pd.DataFrame({'train' : train_loss, 'val':val_loss}).plot(ax=axes[1])\n",
    "    axes[1].set_title('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_onefile(model, criterion, optimizer, epochs, csv_file_no) :\n",
    "    train_dataset, val_dataset = preprocess_onefile(csv_file_no)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "    train_acc, train_loss, val_acc, val_loss = run(model, criterion, optimizer, epochs)\n",
    "\n",
    "    return train_acc, train_loss, val_acc, val_loss\n",
    "\n",
    "def run_all(model, criterion, epochs, log=True) :\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    val_acc = []\n",
    "    val_loss = []\n",
    "\n",
    "    for i in tqdm(range(10)) :\n",
    "        train_dataset, val_dataset = preprocess_onefile(i)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "        t_acc, t_loss, v_acc, v_loss = run(model, criterion, optimizer, epochs, train_dataloader, val_dataloader, False)\n",
    "\n",
    "        if log :\n",
    "            print('--- File No : {} ---'.format(i))\n",
    "            print('Train Loss : {}'.format(sum(t_loss) / epochs))\n",
    "            print('Val Loss : {}'.format(sum(v_loss) / epochs))\n",
    "\n",
    "        train_acc.extend(t_acc)\n",
    "        train_loss.extend(t_loss)\n",
    "        val_acc.extend(v_acc)\n",
    "        val_loss.extend(v_loss)\n",
    "\n",
    "    return train_acc, train_loss, val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Linear1().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_acc, train_loss, val_acc, val_loss = run_all(net, criterion, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(train_acc, train_loss, val_acc, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = torch.load('model.pt').to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "val_acc, val_loss = validate(net2, criterion, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 추론 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocess(test_df) :\n",
    "    drop_columns = ['game_num', 'event_id', 'event_time'] + ['boost{}_timer'.format(i) for i in range(6)] + ['player_scoring_next', 'team_scoring_next']\n",
    "\n",
    "    test_df = test_df.drop(drop_columns, axis=1, errors='ignore')\n",
    "\n",
    "    for i in range(6) :\n",
    "        test_df[f'p{i}_pos_x'].fillna(left, inplace=True)\n",
    "        test_df[f'p{i}_pos_y'].fillna(top, inplace=True)\n",
    "        test_df[f'p{i}_pos_z'].fillna(height, inplace=True)\n",
    "        test_df[f'p{i}_vel_x'].fillna(0, inplace=True)\n",
    "        test_df[f'p{i}_vel_y'].fillna(0, inplace=True)\n",
    "        test_df[f'p{i}_vel_z'].fillna(0, inplace=True)\n",
    "        test_df[f'p{i}_boost'].fillna(0, inplace=True)\n",
    "\n",
    "    test_inputs = test_df.drop(['team_A_scoring_within_10sec', 'team_B_scoring_within_10sec'], axis=1, errors='ignore')\n",
    "\n",
    "    test_inputs = to_tensor(test_inputs)\n",
    "\n",
    "    return TensorDataset(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inputs, t_targets = test_preprocess(read_train_csv(8))\n",
    "t_dataloader = DataLoader(t_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2151840/2151840 [02:25<00:00, 14751.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2151840 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1\n",
       "0        0.0  0.0\n",
       "1        0.0  0.0\n",
       "2        0.0  0.0\n",
       "3        0.0  0.0\n",
       "4        0.0  0.0\n",
       "...      ...  ...\n",
       "2151835  0.0  0.0\n",
       "2151836  0.0  0.0\n",
       "2151837  0.0  0.0\n",
       "2151838  0.0  0.0\n",
       "2151839  0.0  0.0\n",
       "\n",
       "[2151840 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = predict(net2, t_dataloader)\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader) :\n",
    "    model.eval()\n",
    "\n",
    "    predicted = []\n",
    "    with torch.no_grad() :\n",
    "        for (inputs, ) in tqdm(dataloader) :\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.round().cpu().numpy().astype(np.int8)\n",
    "            predicted.extend(preds)\n",
    "\n",
    "    predict_df = pd.DataFrame(predicted)\n",
    "    predict_df.columns = ['team_A_scoring_within_10sec','team_B_scoring_within_10sec']\n",
    "\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('model.pt').to(device)\n",
    "\n",
    "test_dataset = test_preprocess(test_origin)\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701143/701143 [02:09<00:00, 5419.68it/s]\n"
     ]
    }
   ],
   "source": [
    "submission_df = predict(net, test_dataloader)\n",
    "submission_df.index.name = 'id'\n",
    "\n",
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scale_down() :\n",
    "    train_origin = pd.DataFrame()\n",
    "    \n",
    "    for i in tqdm(range(10)) :\n",
    "        tmp_df = read_train_csv(i)\n",
    "\n",
    "        df_1 = pd.concat([tmp_df[tmp_df['team_A_scoring_within_10sec'] == 1], tmp_df[tmp_df['team_B_scoring_within_10sec'] == 1]])\n",
    "        df_0 = tmp_df.drop(df_1.index)\n",
    "\n",
    "        train_origin = pd.concat([train_origin, df_0.sample(len(df_1)), df_1])\n",
    "\n",
    "    return train_origin.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin = load_scale_down()\n",
    "train_origin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\workspaces\\kaggle\\TPS\\2022-10\\run.ipynb 셀 47\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset, val_dataset \u001b[39m=\u001b[39m preprocess_onefile(train_origin)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y104sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_dataset\u001b[39m.\u001b[39;49mtensors\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = preprocess_onefile(train_origin)\n",
    "train_dataset.tensors[0].shape, val_dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Linear1().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch : 0 ---\n",
      "Train Loss : 0.001507525090155439\n",
      "Train Acc : 76.50506059014597\n",
      "--- Epoch : 0 ---\n",
      "Val Loss : 0.001310984281510995\n",
      "Val Acc : 76.5366704372079\n",
      "--- Epoch : 1 ---\n",
      "Train Loss : 0.0012821895399407414\n",
      "Train Acc : 76.75940174280943\n",
      "--- Epoch : 1 ---\n",
      "Val Loss : 0.0013098714200341444\n",
      "Val Acc : 76.53394221628076\n",
      "--- Epoch : 2 ---\n",
      "Train Loss : 0.0012812374691970605\n",
      "Train Acc : 76.76272020558204\n",
      "--- Epoch : 2 ---\n",
      "Val Loss : 0.001308953421121907\n",
      "Val Acc : 76.53462427151254\n",
      "--- Epoch : 3 ---\n",
      "Train Loss : 0.001280475080432055\n",
      "Train Acc : 76.7641105496686\n",
      "--- Epoch : 3 ---\n",
      "Val Loss : 0.0013081954373366218\n",
      "Val Acc : 76.53126646114069\n",
      "--- Epoch : 4 ---\n",
      "Train Loss : 0.001279865288203657\n",
      "Train Acc : 76.76064780590586\n",
      "--- Epoch : 4 ---\n",
      "Val Loss : 0.001307568729918186\n",
      "Val Acc : 76.53089920063127\n",
      "--- Epoch : 5 ---\n",
      "Train Loss : 0.00127937804233493\n",
      "Train Acc : 76.75848359105416\n",
      "--- Epoch : 5 ---\n",
      "Val Loss : 0.0013070496868144467\n",
      "Val Acc : 76.52722659553704\n",
      "--- Epoch : 6 ---\n",
      "Train Loss : 0.0012789890701028564\n",
      "Train Acc : 76.75429944234085\n",
      "--- Epoch : 6 ---\n",
      "Val Loss : 0.0013066189160615882\n",
      "Val Acc : 76.52255714048869\n",
      "--- Epoch : 7 ---\n",
      "Train Loss : 0.0012786787990516242\n",
      "Train Acc : 76.75183354905528\n",
      "--- Epoch : 7 ---\n",
      "Val Loss : 0.0013062606749481137\n",
      "Val Acc : 76.51846480909799\n",
      "--- Epoch : 8 ---\n",
      "Train Loss : 0.0012784315309538044\n",
      "Train Acc : 76.74991854682285\n",
      "--- Epoch : 8 ---\n",
      "Val Loss : 0.001305961973500012\n",
      "Val Acc : 76.5147397382167\n",
      "--- Epoch : 9 ---\n",
      "Train Loss : 0.0012782346503867655\n",
      "Train Acc : 76.74598361072884\n",
      "--- Epoch : 9 ---\n",
      "Val Loss : 0.0013057122659507515\n",
      "Val Acc : 76.51243124358605\n",
      "--- Epoch : 10 ---\n",
      "Train Loss : 0.0012780780916378286\n",
      "Train Acc : 76.74305864156563\n",
      "--- Epoch : 10 ---\n",
      "Val Loss : 0.0013055030633236302\n",
      "Val Acc : 76.50818151483418\n",
      "--- Epoch : 11 ---\n",
      "Train Loss : 0.0012779537541658965\n",
      "Train Acc : 76.7389531915742\n",
      "--- Epoch : 11 ---\n",
      "Val Loss : 0.0013053272061260728\n",
      "Val Acc : 76.5041941150176\n",
      "--- Epoch : 12 ---\n",
      "Train Loss : 0.0012778551253157496\n",
      "Train Acc : 76.73492644030466\n",
      "--- Epoch : 12 ---\n",
      "Val Loss : 0.001305178973356167\n",
      "Val Acc : 76.50146589409046\n",
      "--- Epoch : 13 ---\n",
      "Train Loss : 0.0012777770420708612\n",
      "Train Acc : 76.73074229159135\n",
      "--- Epoch : 13 ---\n",
      "Val Loss : 0.0013050536466133406\n",
      "Val Acc : 76.49852781001509\n",
      "--- Epoch : 14 ---\n",
      "Train Loss : 0.0012777153505729535\n",
      "Train Acc : 76.72763369207708\n",
      "--- Epoch : 14 ---\n",
      "Val Loss : 0.001304947386390056\n",
      "Val Acc : 76.49438301283733\n",
      "--- Epoch : 15 ---\n",
      "Train Loss : 0.0012776667473400553\n",
      "Train Acc : 76.72341019400284\n",
      "--- Epoch : 15 ---\n",
      "Val Loss : 0.0013048570580741464\n",
      "Val Acc : 76.4924417787161\n",
      "--- Epoch : 16 ---\n",
      "Train Loss : 0.0012776285630768719\n",
      "Train Acc : 76.72074755391256\n",
      "--- Epoch : 16 ---\n",
      "Val Loss : 0.001304779957055805\n",
      "Val Acc : 76.49170725769724\n",
      "--- Epoch : 17 ---\n",
      "Train Loss : 0.001277598675014307\n",
      "Train Acc : 76.71791439992487\n",
      "--- Epoch : 17 ---\n",
      "Val Loss : 0.0013047140407075313\n",
      "Val Acc : 76.49097273667842\n",
      "--- Epoch : 18 ---\n",
      "Train Loss : 0.001277575390072152\n",
      "Train Acc : 76.7157633015268\n",
      "--- Epoch : 18 ---\n",
      "Val Loss : 0.0013046574826675668\n",
      "Val Acc : 76.48635574741711\n",
      "--- Epoch : 19 ---\n",
      "Train Loss : 0.001277557336846359\n",
      "Train Acc : 76.71375648411886\n",
      "--- Epoch : 19 ---\n",
      "Val Loss : 0.0013046088097801868\n",
      "Val Acc : 76.48640821320417\n",
      "--- Epoch : 20 ---\n",
      "Train Loss : 0.0012775434347562199\n",
      "Train Acc : 76.71286456527089\n",
      "--- Epoch : 20 ---\n",
      "Val Loss : 0.0013045668048669982\n",
      "Val Acc : 76.4870378026489\n",
      "--- Epoch : 21 ---\n",
      "Train Loss : 0.0012775328160518425\n",
      "Train Acc : 76.71114630984316\n",
      "--- Epoch : 21 ---\n",
      "Val Loss : 0.0013045304548544349\n",
      "Val Acc : 76.48777232366774\n",
      "--- Epoch : 22 ---\n",
      "Train Loss : 0.0012775247827437255\n",
      "Train Acc : 76.70974284930297\n",
      "--- Epoch : 22 ---\n",
      "Val Loss : 0.0013044989229220906\n",
      "Val Acc : 76.48735259737126\n",
      "--- Epoch : 23 ---\n",
      "Train Loss : 0.0012775187907820267\n",
      "Train Acc : 76.70944117086908\n",
      "--- Epoch : 23 ---\n",
      "Val Loss : 0.0013044715094595704\n",
      "Val Acc : 76.48656561056535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\workspaces\\kaggle\\TPS\\2022-10\\run.ipynb 셀 51\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_score \u001b[39m=\u001b[39m run(net, criterion, optimizer, \u001b[39m50\u001b[39;49m, train_dataloader, val_dataloader)\n",
      "\u001b[1;32mc:\\Users\\USER\\workspaces\\kaggle\\TPS\\2022-10\\run.ipynb 셀 51\u001b[0m in \u001b[0;36mrun\u001b[1;34m(model, criterion, optimizer, epochs, train_loader, val_loader, log)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m save_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs) :\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     acc, loss \u001b[39m=\u001b[39m train(model, optimizer, criterion, train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     train_acc\u001b[39m.\u001b[39mappend(acc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(loss)\n",
      "\u001b[1;32mc:\\Users\\USER\\workspaces\\kaggle\\TPS\\2022-10\\run.ipynb 셀 51\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, train_dataloader)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader) :\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     inputs, targets \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/workspaces/kaggle/TPS/2022-10/run.ipynb#Y110sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:84\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39meach element in list of batch should be of equal size\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m     transposed \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m     86\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:84\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39meach element in list of batch should be of equal size\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m     transposed \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m     86\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:56\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel)\n\u001b[0;32m     55\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m     57\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m     58\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     60\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_score = run(net, criterion, optimizer, 50, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(*train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701143/701143 [02:13<00:00, 5251.34it/s]\n"
     ]
    }
   ],
   "source": [
    "net = torch.load('model.pt').to(device)\n",
    "\n",
    "test_dataset = test_preprocess(test_origin)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "submission_df = predict(net, test_dataloader)\n",
    "submission_df.index.name = 'id'\n",
    "\n",
    "submission_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
